{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2abbf203-9414-4959-a9f3-3676a6c3f00f",
   "metadata": {},
   "source": [
    "# importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc1a93c4-88a1-4950-b2cf-bd1647e69f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f8b7ea-ed31-436b-9dbb-fe1f551e6786",
   "metadata": {},
   "source": [
    "# loading and preparing datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae7d03b-4959-46c6-93fd-838f26838756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using a classification dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d98965-5a0c-4518-8856-bfed13566eed",
   "metadata": {},
   "source": [
    "# definig multiple models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7163541-1cd0-4ba2-951a-828dc341410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6053f39b-555c-4a71-a1aa-e23dcace0b5f",
   "metadata": {},
   "source": [
    "# evaluate each model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1d465a2-6335-4c12-a051-f3dd0c014f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Logistic Regression -----\n",
      "Accuracy: 0.956140350877193\n",
      "Precision: 0.9459459459459459\n",
      "Recall: 0.9859154929577465\n",
      "F1 Score: 0.9655172413793104\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94        43\n",
      "           1       0.95      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "----- Random Forest -----\n",
      "Accuracy: 0.9649122807017544\n",
      "Precision: 0.958904109589041\n",
      "Recall: 0.9859154929577465\n",
      "F1 Score: 0.9722222222222222\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "----- SVM -----\n",
      "Accuracy: 0.9473684210526315\n",
      "Precision: 0.922077922077922\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9594594594594594\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.93        43\n",
      "           1       0.92      1.00      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"----- {name} -----\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "for name, model in models.items():\n",
    "    evaluate_model(name, model, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c263d1-dd94-45f2-9d25-b936893a969d",
   "metadata": {},
   "source": [
    "# hyperParameter tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353cf1a4-21c5-4dd1-b172-89cd9e352e03",
   "metadata": {},
   "source": [
    "##  GridSearchCV (Exhaustive Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cf84418-80c4-44f1-ac84-2614aeb5d84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (GridSearch): {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters (GridSearch):\", grid_search.best_params_)\n",
    "best_grid_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a228702-6e4c-43aa-b980-2344a9d03f07",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV (Faster Random Search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c0deed6-da65-48bd-9174-1f292bdfbbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (RandomizedSearch): {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 142}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': [None] + list(np.arange(5, 21)),\n",
    "    'min_samples_split': randint(2, 11)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(), param_dist, n_iter=10, cv=5, scoring='f1', n_jobs=-1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters (RandomizedSearch):\", random_search.best_params_)\n",
    "best_random_model = random_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79e3c0e-1fec-4ca2-abed-3c38dbf899e5",
   "metadata": {},
   "source": [
    "# compare final models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78de7228-1cd8-41c8-8f86-ed8f188d8097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Best GridSearchCV RF -----\n",
      "Accuracy: 0.9649122807017544\n",
      "Precision: 0.958904109589041\n",
      "Recall: 0.9859154929577465\n",
      "F1 Score: 0.9722222222222222\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "----- Best RandomizedSearchCV RF -----\n",
      "Accuracy: 0.9649122807017544\n",
      "Precision: 0.958904109589041\n",
      "Recall: 0.9859154929577465\n",
      "F1 Score: 0.9722222222222222\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model after tuning\n",
    "evaluate_model(\"Best GridSearchCV RF\", best_grid_model, X_train, X_test, y_train, y_test)\n",
    "evaluate_model(\"Best RandomizedSearchCV RF\", best_random_model, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7490a4c4-3229-4d2f-b132-67e47534f2da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
